{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGUbalkBjE2Y6tkAqxKmuT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DokiVamsiKrishna/mynewproject/blob/master/NLP_with_Hugging_Face_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TfjMp_pw-HPv",
        "outputId": "b21053a0-d87b-4742-9591-e31c0666975a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9982457160949707}]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "#SENTIMENT ANALYSIS(Classifies whether the given ststement is positive or negative statement)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModel\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "\n",
        "classifier(\"Having three long haired, heavy shedding dogs at home, I was pretty skeptical that this could hold up to all the hair and dirt they trek in, but this wonderful piece of tech has been nothing short of a godsend for me! \")\n",
        "\n",
        "\n",
        "#classifier(\"i like eating Beef\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TOPIC CLASSIFICATION\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "classifier(\n",
        "    \"My Final year project is based on machine learning and not used deep learning and other technologies\",\n",
        "    candidate_labels=[\"deep learning\", \"machine learning\", \"data analysis\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sDtPk_1-ISA",
        "outputId": "6d6eec0e-13bf-4f7a-c402-6814a4307518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'My Final year project is based on machine learning and not used deep learning and other technologies',\n",
              " 'labels': ['machine learning', 'data analysis', 'deep learning'],\n",
              " 'scores': [0.9785690307617188, 0.010770422406494617, 0.010660518892109394]}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TEXT GENERATOR\n",
        "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "generator(\"This course will teach you\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BI9Pqa4-u-Y",
        "outputId": "c918bf6f-1934-4371-a0e2-47e65e722963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"This course will teach you that your research is invaluable, and that you should take it seriously. After that, you're free to take home the course on the next morning while you're in the room alone. If you're going to take this course\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "generator(\n",
        "    \"AI is now being taught\",\n",
        "    max_length=50,\n",
        "    num_return_sequences=2,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnU_WocH_sWA",
        "outputId": "15be45a6-9c1d-4bf1-adc1-9a0298eb72c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'AI is now being taught the ropes to the real world.'},\n",
              " {'generated_text': \"AI is now being taught with a few questions.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNow, for those questioning, they'll see that this isn't about money, but not about the future of the world. I mean,\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MASKED LANGUAGE MODEL\n",
        "unmasker = pipeline(\"fill-mask\", \"distilroberta-base\")\n",
        "unmasker(\"I would like to tell about some more <mask> models.\", top_k=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duCj5OGB__yp",
        "outputId": "dc86027c-f607-4b3c-b897-aaafa340cd98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.06126723065972328,\n",
              "  'token': 2679,\n",
              "  'token_str': ' interesting',\n",
              "  'sequence': 'I would like to tell about some more interesting models.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#NAME ENTITY RECOGNITION\n",
        "ner = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", grouped_entities=True)\n",
        "ner(\"My name is Vamsi Krishna and I work with C-DAC in Hyderabad\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si4pQWxZA9Pm",
        "outputId": "37f56c92-ca2d-4cbc-c250-8c2aa13e6be0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': 0.9974389,\n",
              "  'word': 'Vamsi Krishna',\n",
              "  'start': 11,\n",
              "  'end': 24},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.99430406,\n",
              "  'word': 'C - DAC',\n",
              "  'start': 41,\n",
              "  'end': 46},\n",
              " {'entity_group': 'LOC',\n",
              "  'score': 0.999271,\n",
              "  'word': 'Hyderabad',\n",
              "  'start': 50,\n",
              "  'end': 59}]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#QUESTION ANSWERING\n",
        "qa_model = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "question = \"Which name is also used to describe the Amazon rainforest in English?\"\n",
        "#context = \"The Amazon rainforest, also known in English as Amazonia or the Amazon Jungle.\"\n",
        "\n",
        "context=\"Amazonia\"\n",
        "qa_model(question = question, context = context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucVkvS4YB0vQ",
        "outputId": "33914e74-94f6-4f47-cbc4-6b13068eb601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.9973620176315308, 'start': 0, 'end': 8, 'answer': 'Amazonia'}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TEXT SUMMARIZER\n",
        "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "Chandrayaan-3 mission took off on July 14, 2023 from the Satish Dhawan Space Centre (SDSC) in Sriharikota, A.P. On August 5, the mission entered the lunar orbit. On August 17, the lander module separated from the propulsion module. The first and second deboosting occurred on August 18 and 20 respectively.\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "w47aEhFKCXRp",
        "outputId": "5dee2a5a-eabe-44df-ab1b-8c73ef085ee2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 142, but your input_length is only 84. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=42)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ' The Chandrayaan-3 mission took off on July 14, 2023 from the Satish Dhawan Space Centre (SDSC) in Sriharikota, A.P. On August 5, the mission entered the lunar orbit . On August 17, the lander module separated from the propulsion module .'}]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Translation of text\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-fr\")\n",
        "translator(\"This is a course about machine learning\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cndeUce0DEnu",
        "outputId": "70286ccf-4f7f-4caa-ac07-c1f082c0fb8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': \"C'est un cours sur l'apprentissage automatique\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ]
}